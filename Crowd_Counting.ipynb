{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i2XL2VKVW_Z"
      },
      "outputs": [],
      "source": [
        "!pip install torch_snippets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_snippets import *\n",
        "import h5py\n",
        "from scipy import io\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from glob import glob \n",
        "from tqdm import tqdm \n",
        "from torch.optim import Adam, lr_scheduler\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "uiMpDxKcLUji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrowdCountingData(Dataset):\n",
        "  def __init__(self, image_dir, heat_map_dir, ground_truth_dir, transformer):\n",
        "    self.image_dir = image_dir\n",
        "    self.heat_map_dir = heat_map_dir\n",
        "    self.ground_truth_dir = ground_truth_dir\n",
        "    self.img_list = stems(image_dir, silent = True)\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    _stem = self.stems[index]\n",
        "    img = f'{self.image_dir}/{_stem}.jpg'\n",
        "    hp =  f'{self.heat_map_dir}/{_stem}.h5'\n",
        "    gt = f'{self.ground_truth_dir}/{_stem}.mat'\n",
        "\n",
        "    pts = io.loadmat(gt)\n",
        "    pts = len(pts['image info'][0,0][0,0][0])\n",
        "    print(pts)\n",
        "\n",
        "    image = read(img, 1)\n",
        "    with h5py.File(hp, 'r') as hf:\n",
        "      gt = hf['density'][:]\n",
        "    gt = resize(gt, 1/8)*64\n",
        "\n",
        "    return image.copy(), gt.copy(), pts\n",
        "  \n",
        "  def collate_fn(self, batch):\n",
        "    ims, gts, pts = list(zip(*batch))\n",
        "    ims = torch.cat([self.transformer(im)[None] for im in ims]).to(device)\n",
        "    gts = torch.cat([self.copy(gt)[None] for gt in gts]).to(device)\n",
        "    pts = torch.tensor(pts).to(device)\n",
        "\n",
        "    return ims, gts, pts"
      ],
      "metadata": {
        "id": "suzaVcoOLqBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_layers(cfg, in_channels = 3, batch_norm = False, dilation = False):\n",
        "  if dilation:\n",
        "    d_rate = 2\n",
        "  else:\n",
        "    d_rate = 1\n",
        "  \n",
        "  layers = []\n",
        "  for v in cfg:\n",
        "    if v == 'M':\n",
        "      layers += [nn.MaxPool2d(kernel_size=2, stride = 2)]\n",
        "    else:\n",
        "      conv2d = nn.Conv2d(in_channels, v, kernel_size = 3, padding = d_rate)\n",
        "      if batch_norm:\n",
        "        layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace = True)]\n",
        "      else:\n",
        "        layers += [conv2d, nn.ReLU(inplace = True)]\n",
        "      in_channels = v\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class CSRNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.frontend_features = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
        "    self.backend_features = [512,512,512,256,128,64]\n",
        "    self.frontend = make_layers(self.frontend_features,batch_norm = True)\n",
        "    self.backend = make_layers(self.backend_features, in_channels = 512, batch_norm = True, dilation = True)\n",
        "    self.output_layer = nn.Conv2d(64, 1, kernel_size = 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.frontend(x)\n",
        "    x = self.backend(x)\n",
        "    x = self.output_layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "SJAzd2-XSOPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(model, data, optimizer, criterion):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  ims, gts, pts = data \n",
        "  _gts = model(ims)\n",
        "  loss = criterion(_gts, gts)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  pts_loss = nn.L1Loss()(_gts.sum(), gts.sum())\n",
        "  return loss.item(), pts_loss.item()\n",
        "\n",
        "def valid_batch(model, data, criterion):\n",
        "  model.eval()\n",
        "  ims, gts, pts = data \n",
        "  _gts = model(ims)\n",
        "  loss = criterion(_gts, gts)\n",
        "  pts_loss = nn.L1Loss()(_gts.sum(), gts.sum())\n",
        "  return loss.item(), pts_loss.item()\n",
        "\n",
        "def get_model():\n",
        "  model = CSRNet().to(device)\n",
        "  optimizer = Adam(model.parameters(), lr = 1e-6)\n",
        "  scheduler = lr_scheduler(optimizer, step_size = 10, gamma = 0.1)\n",
        "  return model, optimizer, scheduler\n",
        "\n",
        "def save_plot(tr_list, val_list, title):\n",
        "  plt.plot(tr_list, label = \"Training\")\n",
        "  plt.plot(val_list, label = \"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "  plt.savefig(f\"{title}.png\")\n",
        "  print(f\"Saved {title}.png\")\n",
        "\n",
        "def run(epoch_range, model_state_dict = None):\n",
        "  transformer = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  image_b_dir = \"\"\n",
        "  image_folder_dir = \"\"\n",
        "  heat_map_dir = \"\"\n",
        "  ground_truth_dir = \"\"\n",
        "\n",
        "  vl_image_b_dir = \"\"\n",
        "  vl_image_folder_dir = \"\"\n",
        "  vl_heat_map_dir = \"\"\n",
        "  vl_ground_truth_dir = \"\"\n",
        "\n",
        "  tr_set = CrowdCountingData()\n",
        "  vr_set = CrowdCountingData()\n",
        "  tr_loader = DataLoader(tr_set, batch_size = 16, shuffle = True, collate_fn = tr_set.collate_fn)\n",
        "  vr_loader = DataLoader(vr_set, batch_size = 16, shuffle = True, colalte_fn = vr_set.collate_fn)\n",
        "\n",
        "  model, optimizer, scheduler = get_model()\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "  min_validation_loss = 1\n",
        "  print(\"---------------------------------------------------------\")\n",
        "  for epoch in range(epoch_range):\n",
        "    tr_loss = []\n",
        "    for bx, data in enumerate(tqdm(tr_loader, desc = \"TRAINING\")):\n",
        "      loss, pt = train_batch(model, data, optimizer, criterion)\n",
        "      tr_loss.append(loss)\n",
        "    tr_loss_value = np.mean(tr_loss_value)\n",
        "    training_loss.append(tr_loss_value)\n",
        "\n",
        "    vl_loss = []\n",
        "    for bx, data in enumerate(tqdm(vr_loader, desc = \"VALIDATION\")):\n",
        "      loss, pt = valid_batch(model, data, criterion)\n",
        "      vl_loss.append(loss)\n",
        "    vl_loss_value = np.mean(vl_loss)\n",
        "    validation_loss.append(vl_loss_value)\n",
        "\n",
        "    print(\"\\nEpoch: {}/{} | Average Training Loss: {:.4f} | Average Validation Loss: {:.4f}\".format(\n",
        "      epoch+1,\n",
        "      epoch_range,\n",
        "      tr_loss_value, \n",
        "      vl_loss_value,\n",
        "    ))\n",
        "\n",
        "    if min_validation_loss > vl_loss_value:\n",
        "      min_validation_loss = vl_loss_value\n",
        "      torch.save(model.state_dict(),f'Epoch_{epoch+1}_model.pth')\n",
        "      print(\"New Model Saved!\")\n",
        "\n",
        "  save_plot(training_loss, validation_loss, \"LOSS\")"
      ],
      "metadata": {
        "id": "qP1P0bShXfEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  run(100)"
      ],
      "metadata": {
        "id": "aZwrPpKDfKfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}