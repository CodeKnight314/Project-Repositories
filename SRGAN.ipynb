{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_snippets"
      ],
      "metadata": {
        "id": "rGweN9qwA1lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_ssim "
      ],
      "metadata": {
        "id": "hd8-mkBOcnor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"SRGAN\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1CsyvA790GM30uX1J3wnSnfoTGSQLXrr9\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from torch_snippets import *\n",
        "from torchvision.models import vgg19, VGG19_Weights\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torchsummary import summary\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_ssim\n",
        "import numpy as np\n",
        "from math import log10\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class SuperResolutionDatasetTrain(Dataset):\n",
        "  def __init__(self, data_dir):\n",
        "    super().__init__()\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    self.image_files = glob(data_dir + \"/*.png\")\n",
        "    self.lr_transform = T.Compose(\n",
        "        [   \n",
        "            T.ToPILImage(),\n",
        "            T.Resize((96 // 4, 96 // 4), InterpolationMode.BICUBIC),\n",
        "            T.ToTensor(),\n",
        "        ])\n",
        "    self.hr_transform = T.Compose(\n",
        "        [\n",
        "            T.RandomCrop(96),\n",
        "            T.Resize((96, 96)),\n",
        "            T.ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_files)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.image_files[index]).convert(\"RGB\")\n",
        "    hr_image = self.hr_transform(img)\n",
        "    lr_image = self.lr_transform(hr_image)\n",
        "\n",
        "    return hr_image.to(device), lr_image.to(device)\n",
        "\n",
        "class SuperResolutionDatasetTest(Dataset):\n",
        "  def __init__(self, gt_data_dir, lr_data_dir):\n",
        "    super().__init__()\n",
        "    self.gt_data_dir = sorted(glob(gt_data_dir + \"/*\"))\n",
        "    self.lr_data_dir = sorted(glob(lr_data_dir + \"/*\"))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.gt_data_dir)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    gt_image = Image.open(self.gt_data_dir[index]).convert(\"RGB\")\n",
        "    lr_image = Image.open(self.lr_data_dir[index]).convert(\"RGB\")\n",
        "\n",
        "    transformer = T.Compose([\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "\n",
        "    gt_image = transformer(gt_image)\n",
        "    lr_image = transformer(lr_image)\n",
        "    \n",
        "    return gt_image.to(device), lr_image.to(device)\n",
        "    \n",
        "class Residual_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        nn.Conv2d(channels, channels,(3,3),(1,1),(1,1),bias = False),\n",
        "        nn.BatchNorm2d(channels),\n",
        "        nn.PReLU(),\n",
        "        nn.Conv2d(channels, channels,(3,3),(1,1),(1,1),bias = False), \n",
        "        nn.BatchNorm2d(channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = self.block(x)\n",
        "    return torch.add(x, residual)\n",
        "\n",
        "class Upsample_Block(nn.Module):\n",
        "  def __init__(self, channels, upscale_factor): \n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        nn.Conv2d(channels, channels * upscale_factor ** 2, kernel_size = (3,3), stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(channels * 2 ** 2),\n",
        "        nn.PixelShuffle(2),\n",
        "        nn.PReLU()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.pre_res = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 9, stride = 1, padding = 4), #check what impact removing padding has\n",
        "        nn.PReLU()\n",
        "    )\n",
        "    \n",
        "    res_block = []\n",
        "    for _ in range(16):\n",
        "        res_block.append(Residual_Block(64))\n",
        "    self.res_blocks = nn.Sequential(*res_block)\n",
        "    \n",
        "    self.pos_res = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, (3,3), (1,1), (1,1)), \n",
        "        nn.BatchNorm2d(64), \n",
        "    )\n",
        "\n",
        "    up_sample = [] \n",
        "    for _ in range(int(math.log(4,2))):\n",
        "        up_sample.append(Upsample_Block(64,2))\n",
        "    self.upsampling = nn.Sequential(*up_sample)\n",
        "\n",
        "    self.pos_up = nn.Conv2d(64,3, kernel_size = (9,9), stride = (1,1), padding = (4,4))\n",
        "    \n",
        "    self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.pre_res(x)\n",
        "    out = self.res_blocks(out1)\n",
        "    out2 = self.pos_res(out)\n",
        "    out = torch.add(out1, out2) \n",
        "    out = self.upsampling(out)\n",
        "    out = self.pos_up(out)\n",
        "\n",
        "    out = torch.clamp_(out, 0.0, 1.0)\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def _initialize_weights(self) -> None:\n",
        "    for module in self.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "        elif isinstance(module, nn.BatchNorm2d):\n",
        "            nn.init.constant_(module.weight, 1)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # input size. (3) x 128 x 128\n",
        "            nn.Conv2d(3, 64, (3, 3), (1, 1), (1, 1), bias=True),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            # state size. (64) x 64 x 64\n",
        "            nn.Conv2d(64, 64, (4, 4), (2, 2), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(64, 128, (3, 3), (1, 1), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            # state size. (128) x 32 x 32\n",
        "            nn.Conv2d(128, 128, (4, 4), (2, 2), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(128, 256, (3, 3), (1, 1), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            # state size. (256) x 16 x 16\n",
        "            nn.Conv2d(256, 256, (4, 4), (2, 2), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(256, 512, (3, 3), (1, 1), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            # state size. (512) x 8 x 8\n",
        "            nn.Conv2d(512, 512, (4, 4), (2, 2), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(512, 512, (3, 3), (1, 1), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            # state size. (512) x 4 x 4\n",
        "            nn.Conv2d(512, 512, (4, 4), (2, 2), (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(4608, 100),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.features(x)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "class PerceptualLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(PerceptualLoss, self).__init__()\n",
        "\n",
        "      vgg = vgg19(pretrained=True)\n",
        "      loss_network = nn.Sequential(*list(vgg.features)[:35]).eval()\n",
        "      for param in loss_network.parameters():\n",
        "          param.requires_grad = False\n",
        "      self.loss_network = loss_network\n",
        "      self.l1_loss = nn.L1Loss()\n",
        "\n",
        "  def forward(self, high_resolution, fake_high_resolution):\n",
        "      perception_loss = self.l1_loss(self.loss_network(high_resolution), self.loss_network(fake_high_resolution))\n",
        "      return perception_loss\n",
        "\n",
        "def define_loss():\n",
        "  pixel_loss = nn.MSELoss()\n",
        "  content_loss = PerceptualLoss()\n",
        "  adversarial_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  pixel_loss = pixel_loss.to(device)\n",
        "  content_loss = content_loss.to(device)\n",
        "  adversarial_loss = adversarial_loss.to(device)\n",
        "\n",
        "  return pixel_loss, content_loss, adversarial_loss\n",
        "\n",
        "def get_optimizers(netD, netG):\n",
        "  optimizer_d = Adam(netD.parameters(),lr = 1e-4)\n",
        "  optimizer_g = Adam(netG.parameters(),lr = 1e-4)\n",
        "  return optimizer_d, optimizer_g\n",
        "\n",
        "def get_lr_scheduler(opt_d, opt_g, epoch_range):\n",
        "  lr_d = lr_scheduler.StepLR(opt_d, epoch_range//2, gamma = 0.1)\n",
        "  lr_g = lr_scheduler.StepLR(opt_g, epoch_range//2, gamma = 0.1)\n",
        "  return lr_d, lr_g\n",
        "\n",
        "def load_dataset(train_data_dir, test_data_dir):\n",
        "  tr_ds = SuperResolutionDatasetTrain(train_data_dir)\n",
        "  ts_ds = SuperResolutionDatasetTest(test_data_dir)\n",
        "  tr_dl = DataLoader(tr_ds, batch_size = 64, shuffle = True)\n",
        "  ts_dl = DataLoader(ts_ds, batch_size = 16, shuffle = False) \n",
        "\n",
        "  return tr_dl, ts_dl\n",
        "\n",
        "def train(model_d, model_g, opt_d, opt_g,data):\n",
        "    model_d.train()\n",
        "    model_g.train()\n",
        "    hr, lr = data\n",
        "\n",
        "    batch_size, _, height, width = hr.shape\n",
        "\n",
        "    real_label = torch.full([batch_size,1],1.0, dtype = hr.dtype).to(device)\n",
        "    fake_label = torch.full([batch_size,1],0.0, dtype = hr.dtype).to(device)\n",
        "  \n",
        "    pixel_criterion, content_criterion, adversarial_criterion = define_loss() \n",
        "\n",
        "    #Discriminator\n",
        "    for d in model_d.parameters():\n",
        "        d.requires_grad = True \n",
        "    model_d.zero_grad(set_to_none=True) \n",
        "    gt_output = model_d(hr)\n",
        "    d_loss_gt = adversarial_criterion(gt_output, real_label) \n",
        "    d_loss_gt.backward(retain_graph = True)\n",
        "\n",
        "    sr = model_g(lr)\n",
        "    sr_output = model_d(sr.detach().clone())\n",
        "    d_loss_sr = adversarial_criterion(sr_output, fake_label) \n",
        "    d_loss_sr.backward()\n",
        "\n",
        "    d_loss = d_loss_gt + d_loss_sr \n",
        "    opt_d.step()\n",
        "\n",
        "    for d in model_d.parameters():\n",
        "        d.requires_grad = False \n",
        "\n",
        "    #Generator\n",
        "    model_g.zero_grad(set_to_none=True)\n",
        "    pixel_loss = pixel_criterion(sr, hr)\n",
        "    content_loss = content_criterion(sr, hr) \n",
        "    adversarial_loss = adversarial_criterion(model_d(sr), real_label) * 0.001\n",
        "\n",
        "    g_loss = pixel_loss + content_loss + adversarial_loss \n",
        "    g_loss.backward()\n",
        "    opt_g.step() \n",
        "\n",
        "    d_gt_probaility = torch.sigmoid(torch.mean(gt_output.detach()))\n",
        "    d_sr_probaility = torch.sigmoid(torch.mean(sr_output.detach()))\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return d_loss.item(), g_loss.item(), d_gt_probaility.item(), d_sr_probaility.item()  \n",
        "\n",
        "def test(model_d, model_g, data, epoch):\n",
        "  model_d.eval()\n",
        "  model_g.eval()\n",
        "\n",
        "  hr, lr = data\n",
        "\n",
        "  with torch.no_grad():\n",
        "    gen_sr = model_g(lr) \n",
        "\n",
        "  mse = torch.mean((hr * 255 - gen_sr * 255) ** 2 + 1e-8, dim = [1,2,3])\n",
        "  psnr = 10 * torch.log10_((255.0 ** 2) / mse)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    plot_train_result(hr, gen_sr, lr, epoch, save = True, show = False)\n",
        "\n",
        "  return psnr\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "def plot_train_result(real_image, gen_image, recon_image, epoch=1, save=False,  show=True, fig_size=(15, 15)):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=fig_size)\n",
        "    imgs = [to_np(real_image)[0], to_np(gen_image)[0], to_np(recon_image)[0]]\n",
        "    for ax, img in zip(axes.flatten(), imgs):\n",
        "        ax.axis('off')\n",
        "        img = img.squeeze()\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    title = 'Epoch {0}'.format(epoch + 1)\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "\n",
        "    if save:\n",
        "        save_fn = 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "def live_practice(image_dir, output_dir, model_pth):\n",
        "  model = Generator().to(device)\n",
        "  model.load_state_dict(torch.load(model_pth))\n",
        "  model.eval()\n",
        "  ds = SuperResolutionDataset(image_dir)\n",
        "  dl = DataLoader(ds, shuffle = True)\n",
        "  for ix, data in enumerate(dl):\n",
        "    hr, lr = data\n",
        "    gen_hr = model(lr)\n",
        "    save_image(gen_hr, f\"{output_dir}/{ix+1}_sr.png\",normalize = True)\n",
        "    save_image(hr, f\"{output_dir}/{ix+1}_hr.png\",normalize = True)\n",
        "    save_image(lr, f\"{output_dir}/{ix+1}_lr.png\",normalize = True)\n",
        "\n",
        "  print(\"[INFO] FINISHED CONVERTING IMAGES TO HIGH RESOLUTION\")\n",
        "\n",
        "def make_img_grids(img_lr, img_hr, gen_hr, output_dir,epoch):\n",
        "  img_lr = nn.functional.interpolate(img_lr, scale_factor = 4)\n",
        "  img_hr = make_grid(img_hr, nrow = 1, normalize = True)\n",
        "  gen_hr = make_grid(gen_hr, nrow = 1, normalize = True)\n",
        "  img_lr = make_grid(img_lr, nrow = 1, normalize = True)\n",
        "  img_grid = torch.cat([img_lr, img_hr, gen_hr])\n",
        "  save_image(img_grid, f\"{output_dir}/grid_results_{epoch}.png\", normalize = False)\n",
        "\n",
        "def main():\n",
        "  epoch_range = 200\n",
        "\n",
        "  training_dl, testing_dl = load_dataset(\"C:/Users/richa/source/repos/Data/Image Resolution/train\",\"C:/Users/richa/source/repos/Data/Image Resolution/test\")\n",
        "\n",
        "  log = Report(epoch_range)\n",
        "  model_g = Generator().to(device)\n",
        "  model_d = Discriminator().to(device)\n",
        "\n",
        "  summary(model_g, (3,24,24))\n",
        "  summary(model_d, (3,96,96))\n",
        "\n",
        "  opt_d, opt_g = get_optimizers(model_d, model_g)\n",
        "  lr_d, lr_g = get_lr_scheduler(opt_d, opt_g, epoch_range)\n",
        "  print(\"[INFO] SRGAN MODEL BUILT\")\n",
        "  print(\"[INFO] DATASETS LOADED\")\n",
        "  print(\"[INFO] OPTIMIZERS AND SCHEDULERS BUILT\")\n",
        "  print(f\"[INFO] CURRENTLY USING {device}\")\n",
        "\n",
        "  for epoch in range(epoch_range):\n",
        "    N = len(training_dl)\n",
        "    for i, data in enumerate(training_dl):\n",
        "      d_loss, g_loss, d_gt, d_sr  = train(model_d, model_g, opt_d, opt_g, data)\n",
        "      log.record(epoch + (1+i)/N, d_loss = d_loss, g_loss = g_loss,d_gt = d_gt, d_sr = d_sr, end = \"/r\")\n",
        "      del d_loss, g_loss, d_gt, d_sr\n",
        "    \n",
        "    N = len(testing_dl)\n",
        "    for i, data in enumerate(testing_dl):\n",
        "      psnr = test(model_d,model_g,data, epoch)\n",
        "      log.record(epoch + (1+i)/N, psnr = psnr, end = \"/r\")\n",
        "      del psnr\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    if(epoch % 10 == 0):\n",
        "      torch.save(model_g.state_dict(), f\"Epoch_{epoch}_model_g.pth\")\n",
        "      torch.save(model_d.state_dict(), f\"Epoch_{epoch}_model_d.pth\")\n",
        "\n",
        "    log.report_avgs(epoch+1)\n",
        "\n",
        "  log.plot_epochs(['d_loss','g_loss'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  model_g = Generator().to(device)\n",
        "  model_d = Discriminator().to(device)\n",
        "\n",
        "  summary(model_g, (3,24,24))\n",
        "  summary(model_d, (3,96,96))\n"
      ],
      "metadata": {
        "id": "KiM1mtVTafWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}