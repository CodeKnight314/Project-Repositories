{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvxTOm8R7Wo9"
      },
      "outputs": [],
      "source": [
        "!pip -q install torch_snippets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_snippets import *\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "2NSUH9cU7csL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "dataloader = DataLoader(MNIST('/content/',download = True, train = True, transform = transforms), shuffle = True, drop_last = True, batch_size = 128)"
      ],
      "metadata": {
        "id": "VUCyNrQA7ywM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(784, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "class Generator(nn.module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(100, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 784),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "def noise(size):\n",
        "  n = torch.randn(size, 100)\n",
        "  return n.to(device)\n",
        "\n",
        "def discriminator_train_step(real_data, fake_data):\n",
        "  d_optimizer.zero_grad()\n",
        "  prediction_real = discriminator(real_data)\n",
        "  error_real = loss(prediction_real, torch.ones(len(real_data), 1).to(device))\n",
        "  error_real.backward()\n",
        "  prediction_fake = discriminator(fake_data)\n",
        "  error_fake = loss(prediction_fake, torch.zeros(len(fake_data), 1).to(device))\n",
        "  error_fake.backward()\n",
        "  d_optimizer.step()\n",
        "  return error_fake + error_real\n",
        "\n",
        "def generator_train_step(fake_data):\n",
        "  g_optimizer.zero_grad()\n",
        "  prediction = discriminator(fake_data)\n",
        "  error = loss(prediction, torch.ones(len(real_data), 1).to(device))\n",
        "  error.backward()\n",
        "  g_optimizer.step()\n",
        "  return error\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator().to(device)\n",
        "d_optimizer = Adam(discriminator.parameters(), lr = 0.0002)\n",
        "g_optimizer = Adam(generator.parameters(), lr = 0.0002)\n",
        "loss = nn.BCELoss()\n",
        "num_epochs = 200\n",
        "log = Report(num_epochs)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  N = len(dataloader)\n",
        "  for i, (image, _) in enumerate(tqdm(dataloader)):\n",
        "    real_data = image.view(len(image),-1).to(device)\n",
        "    fake_data = generator(noise(len(real_data))).to(device)\n",
        "    fake_data = fake_data.detach()\n",
        "\n",
        "    d_loss = discriminator(real_data, fake_data)\n",
        "    fake_data = generator(noise(len(real_data))).to(device)\n",
        "    g_loss = generator_train_step(fake_data)\n",
        "    log.record(epoch + (1+i)/N, d_loss = d_loss.item(), g_loss = g_loss.item(), end = '/r')\n",
        "  log.report_avgs(epoch+1)\n",
        "log.plot_epochs(['d_loss','g_loss'])"
      ],
      "metadata": {
        "id": "18T2huPM8MIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(64,100).to(device)\n",
        "sample_images = generator(z).data.cpu().view(64, 1, 28 , 28)\n",
        "grid = make_grid(sample_images, nrow = 8, normalize=True)\n",
        "show(grid.cpu().detach().permute(1,2,0), sz = 5)"
      ],
      "metadata": {
        "id": "J2YBcAv3ATzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}