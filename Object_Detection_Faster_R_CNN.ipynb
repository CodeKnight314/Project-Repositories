{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn \n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from glob import glob\n",
        "from torch_snippets import *\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  w_and_h = (224,224)\n",
        "  def __init__(self, df, root_directory, transformer = None):\n",
        "    self.df = df\n",
        "    self.files = glob(root_directory + \"/*.jpg\")\n",
        "    self.transformer = transformer\n",
        "    self.label2name = {l:t+1 for t, l in enumerate(self.df('LabelName').unique())}\n",
        "    self.label2name['background'] = 0\n",
        "    self.name2label = {t:l for l, t in self.label2name.items()}\n",
        "    self.num_of_classes = len(self.label2name)\n",
        "    self.image_id = self.df.ImageID.unique()\n",
        "  \n",
        "  def collate_fn(self, batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_id)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #Loading image_id and corresponding image\n",
        "    image_id = self.image_id[index]\n",
        "    image_path = find(image_id, self.files)\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    if self.transformer:\n",
        "      img = self.transformer(img).permute(2,0,1)\n",
        "    else:\n",
        "      img = torch.tensor(img).permute(2,0,1)\n",
        "    \n",
        "    #Grabbing labels and box data\n",
        "    data = self.df[self.df['ImageID'] == image_id]\n",
        "    labels = data['LabelName'].values.tolist()\n",
        "    print(labels)\n",
        "    data = data[['XMin', 'YMin','XMax','YMAX']].values\n",
        "\n",
        "    #Moving coordinates into absolute coordinate values\n",
        "    data[:, [0,2]] *= self.w_and_h[0]\n",
        "    data[:, [1,3]] *= self.w_and_h[1]\n",
        "\n",
        "    boxes = data.astype(np.unit32).tolist()\n",
        "\n",
        "    target = {}\n",
        "    target['boxes'] = torch.tensor(boxes).float().to(device)\n",
        "    target['labels'] = torch.tensor([self.label2target[i] for i in labels]).long().to(device)\n",
        "\n",
        "    return img.to(device), target"
      ],
      "metadata": {
        "id": "R3Ofgmj2zQHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(num_of_classes):\n",
        "  model = torchvision.models.detection.fasterrcnn_resenet50_fpn(pretrained = True)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_of_classes)\n",
        "  return model\n",
        "\n",
        "def train(inputs, model, optimizer):\n",
        "  model.train()\n",
        "  input, targets = inputs\n",
        "  optimizer.zero_grad()\n",
        "  losses = model(input, targets)\n",
        "  loss = sum(loss for loss in losses.value())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss, losses\n",
        "\n",
        "def train_epoch(n_epochs, model, optimizer)"
      ],
      "metadata": {
        "id": "LyPwCaCo6h8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"main\":\n",
        "  training_directory = \"\"\n",
        "  validation_directory = \"\"\n",
        "  batch_size = \"\"\n",
        "  df_raw = \"\"\n",
        "  batch_size = 16\n",
        "  n_epochs = 100\n",
        "\n",
        "  tr_transformer = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.RandomHorizontalFlip(0.2),\n",
        "      transforms.RandomVerticalFlip(0.2),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "  ])\n",
        "\n",
        "  vl_transformer = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  print(\"Loading Dataset: Training\")\n",
        "  tr_set = ImageDataset(df_raw, training_directory, tr_transformer)\n",
        "  print(\"Loading Data to Loader: Training\")\n",
        "  tr_dl = DataLoader(tr_set,batch_size = batch_size, shuffle = True, drop_last = True, collate_fn=tr_set.collate_fn())\n",
        "  \n",
        "  \n",
        "  model = get_model().to(device)\n",
        "  optimizer = Adam(model.parameters(),lr = 1e-3,momentum = 0.9,weight_decay=0.0005)\n",
        "  log = Report(n_epochs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2x0v97Ke6WDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}