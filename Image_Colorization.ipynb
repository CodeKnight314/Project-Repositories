{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch_snippets import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "3OvGtK2aDYGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Colorize(torchvision.datasets.CIFAR10):\n",
        "  def __init__(self, root, train):\n",
        "    super().__init__(root, train)\n",
        "      \n",
        "  def __getitem__(self, ix):\n",
        "    im, _ = super().__getitem__(ix)\n",
        "    bw = im.convert('L').convert('RGB')\n",
        "    bw, im = np.array(bw)/255., np.array(im)/255.\n",
        "    bw, im = [torch.tensor(i).permute(2,0,1).to(device).float() for i in [bw,im]]\n",
        "    return bw, im"
      ],
      "metadata": {
        "id": "1u0CNZPaEFOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, maxPool = True):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.MaxPool2d(2) if maxPool else Identity(),\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.convtranspose = nn.ConvTranspose2d(in_channels, out_channels, 2, stride = 2)\n",
        "    self.convLayer = nn.Sequential(\n",
        "        nn.Conv2d(out_channels + out_channels, out_channels, 3, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    x = self.convtranspose(x)\n",
        "    x = torch.cat([x,y], axis = 1)\n",
        "    x = self.convLayer(x)\n",
        "    return x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.d1 = DownConv(3, 64, False)\n",
        "    self.d2 = DownConv(64, 128)\n",
        "    self.d3 = DownConv(128, 256)\n",
        "    self.d4 = DownConv(256, 512)\n",
        "    self.d5 = DownConv(512, 1024)\n",
        "\n",
        "    self.u5 = UpConv(1024, 512)\n",
        "    self.u4 = UpConv(512, 256)\n",
        "    self.u3 = UpConv(256, 128)\n",
        "    self.u2 = UpConv(128, 64)\n",
        "    self.u1 = nn.Conv2d(64, 3, kernel_size=1, stride = 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x0 = self.d1( x) # 32\n",
        "    x1 = self.d2(x0) # 16\n",
        "    x2 = self.d3(x1) # 8\n",
        "    x3 = self.d4(x2) # 4\n",
        "    x4 = self.d5(x3) # 2\n",
        "    X4 = self.u5(x4, x3)# 4\n",
        "    X3 = self.u4(X4, x2)# 8\n",
        "    X2 = self.u3(X3, x1)# 16\n",
        "    X1 = self.u2(X2, x0)# 32\n",
        "    X0 = self.u1(X1) # 3\n",
        "\n",
        "    return X0"
      ],
      "metadata": {
        "id": "et6RmTWYF-ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  model = UNET().to(device)\n",
        "  optimizer = Adam(model.parameters(), lr = 1e-6)\n",
        "  loss_fn = nn.MSELoss()\n",
        "  return model, optimizer, loss_fn\n",
        "\n",
        "def get_data_loaders(data_folder):\n",
        "  datasets.CIFAR10(data_folder, download = True, train = True)\n",
        "  tr_set = Colorize(data_folder, train = True)\n",
        "  vl_set = Colorize(data_folder, train = False)\n",
        "  tr_dl = DataLoader(tr_set, batch_size = 256, shuffle = True, drop_last = True)\n",
        "  vl_dl = DataLoader(vl_set, batch_size = 256, shuffle = True, drop_last = True)\n",
        "  return tr_dl, vl_dl\n",
        "\n",
        "def train_batch(model, optimizer, loss_function, data):\n",
        "  model.train()\n",
        "  x, y = data\n",
        "  _y = model(x)\n",
        "  optimizer.zero_grad()\n",
        "  loss_value = loss_function(_y, y)\n",
        "  loss_value.backward()\n",
        "  optimizer.step()\n",
        "  return loss_value.item()\n",
        "\n",
        "def valid_batch(model, loss_function, data):\n",
        "  model.eval() \n",
        "  x, y = data\n",
        "  _y = model(x)\n",
        "  loss_value = loss_function(_y, y)\n",
        "  return loss_value.item()\n",
        "\n",
        "def save_plot(tr_list, val_list, title):\n",
        "  plt.plot(tr_list, label = \"Training\")\n",
        "  plt.plot(val_list, label = \"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "  plt.savefig(f\"{title}.png\")\n",
        "  print(f\"Saved {title}.png\")\n",
        "\n",
        "def run(epoch_range, data_folder, model_dict = None):\n",
        "  model, optimizer, loss_fn = get_model()\n",
        "  tr_dl, vl_dl = get_data_loaders(data_folder)\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)\n",
        "  log = Report(epoch_range)\n",
        "  min_loss = 10\n",
        "  for epoch in range(epoch_range):\n",
        "    N = len(tr_dl);    \n",
        "    for bx, data in enumerate(tr_dl):\n",
        "      loss = train_batch(model, optimizer, loss_fn, data)\n",
        "      log.reocrd(epoch + (1+bx)/N, loss = loss, end = \"/r\")\n",
        "      del loss\n",
        "\n",
        "    N = len(vl_dl)\n",
        "    val_loss_avg = 0\n",
        "    for bx, data in enumerate(vl_dl):\n",
        "      val_loss = valid_batch(model, loss_fn, data)\n",
        "      val_loss_avg+=val_loss\n",
        "      log.record(epoch + (bx + 1)/N, val_loss = val_loss, end = \"/r\")\n",
        "      del loss\n",
        "    log.report_avgs(epoch+1)\n",
        "    val_loss = val_loss/N\n",
        "    if min_loss > val_loss:\n",
        "      min_loss = val_loss\n",
        "      torch.save(f\"Epoch {epoch+1}\")"
      ],
      "metadata": {
        "id": "tRlo8vh1JtqN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}